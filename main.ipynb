{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extraordinary-signal",
   "metadata": {},
   "source": [
    "# K-Prototypes Tech Talk\n",
    "# By Palermo Penano\n",
    "\n",
    "The summary below closely follows the original paper, [Huang 1998](https://link.springer.com/article/10.1023/A:1009769707641).\n",
    "\n",
    "## Outline\n",
    "* Unsupervised machine learning and what does it mean to cluster data\n",
    "    * How does regular K-means work?\n",
    "    * Other clustering algos\n",
    "* What are its advantages and limitations\n",
    "* Why is using standard distance metric problematic?\n",
    "* K-prototypes\n",
    "* What libraries are available?\n",
    "* Application to Colombia vulnerability index\n",
    "\n",
    "## References\n",
    "\n",
    "* Python implementation\n",
    "    * https://pypi.org/project/kmodes/\n",
    "    * https://github.com/nicodv/kmodes\n",
    "* Other articles and notebooks using k-prototypes\n",
    "    * https://www.kaggle.com/rohanadagouda/unsupervised-learning-using-k-prototype-and-dbscan\n",
    "    * https://towardsdatascience.com/the-k-prototype-as-clustering-algorithm-for-mixed-data-type-categorical-and-numerical-fe7c50538ebb\n",
    "\n",
    "* Data for this demo\n",
    "    * https://www.kaggle.com/giovamata/airlinedelaycauses\n",
    "* [Unsupervised clustering with mixed categorical and continuous data](https://www.tomasbeuzen.com/post/clustering-mixed-data/)\n",
    "    \n",
    "https://www.kaggle.com/ashydv/bank-customer-clustering-k-modes-clustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-coral",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How does K-means work\n",
    "\n",
    "### K-means algorithm\n",
    "* Initialize with a random set of cluster vectors (these are m-dimensional vectors where m is the number of features in the dataset)\n",
    "* In a loop:\n",
    "    * Allocate each point in the data to the nearest cluster based on the Euclidean distance\n",
    "    * For each cluster, update the cluster vector by calculating the mean of all the records assigned to that cluster (average of each component across all vectors belonging to the same cluster).\n",
    "    * Repeat the first step by checking and reallocating each data point based on the new cluster vectors\n",
    "    * Repeat until desired number of iteration is reached or record changes cluster\n",
    "    \n",
    "Here's a visualization of the algorithm\n",
    "    \n",
    "    \n",
    "![kmeans_algo](./imgs/kmeans_algo.png)\n",
    "[Source](https://en.wikipedia.org/wiki/K-means_clustering)\n",
    "\n",
    "## Why K-means shouldn't be used with categorical variables\n",
    "\n",
    "Categorical variables are data that takes one of a limited and usually fixed number of possible values. If they can be ordered, then it is called `ordinal`. If it cannot be ordered, then it is called `nominal`. Here are some examples:\n",
    "\n",
    "    * ordinal: risk rating, rank, day of the week\n",
    "    * nominal: political party, region of residence, occupation\n",
    "\n",
    "There are several ways these variables are used in models. For unsupervised ML, some approaches include one-hot encoding, label encoding, feature aggregation, or excluding the feature from the model.\n",
    "\n",
    "For one-hot encoding, the categorical is converted to several binary features each of which representing a given category in the original feature. This works when there are few categories, but become a computational burden when categories exceeds hundres or thousands of unique values (e.g. zip codes).\n",
    "\n",
    "Label encoding only works for ordinal data, but even in such case it would require that the encoded feature follows the same ordering as the original values in the raw feature.\n",
    "\n",
    "In the case of a categorical feature with high cardinality, one solution is to aggregate them. For example, zip codes can be aggregated to a region containing many zip codes. Following the aggregation, one can then apply one-hot encoding.\n",
    "\n",
    "When the approaches above fails or is infeasible to apply, the data scientist may exclude categorical feature all together from the model.\n",
    "\n",
    "## Why is using standard distance metric problematic for categorical data?\n",
    "\n",
    "\n",
    "For numerical data, it is natural to define the center of mass for a collection of points using common distance metrics, such as the Euclidean distance. Say you have three points in your dataset containing annual income: `[$100k, $45k, $65k]`. One metric for the center of mass is just the average, in this case, `$70k`. \n",
    "\n",
    "But instead of income, suppose you had categories of hair color: `[blond, red, black]`. How can one define center of mass in this case?\n",
    "\n",
    "\n",
    "## K-prototypes\n",
    "\n",
    "K-prototypes combines k-means and k-modes into to be able to handle both numeric and cateogircal variables. The k-modes algorithm differs from k-means in the following way:\n",
    "\n",
    "- Instead of Euclidean distance, use an alternative dissimilarity measure for categorical objects\n",
    "- Instead of mean of a set of points to define a cluster centroid, use the mode where a frequency-based approach to find modes for the clusters\n",
    "\n",
    "\n",
    "### K-modes\n",
    "\n",
    "Dissimilarity measure for categorical attributes\n",
    "\n",
    "```\n",
    "x1 = [finance, married, golf] \n",
    "\tis similar to \n",
    "x2 = [finance, married, squash] \n",
    "\tbut dissimilar to \n",
    "x3 = [healthcare, single, soccer]\n",
    "```\n",
    "\n",
    "More formally,\n",
    "\n",
    "<img src=\"./imgs/dissimilarity_measure.png\" alt=\"drawing\" width=\"250\"/>\n",
    "\n",
    "Use the mode to represent the \"center\" of a set of vectors containing only categoricals. The mode itself need not be part of the original set. The formal definition for the mode is a vector Q such that this Q minimizes the distance between itself and the other vectors in the set using the dissimilarity measure above.\n",
    "\n",
    "More formally\n",
    "\n",
    "<img src=\"./imgs/cat_mode.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Now that we have an approach for defining how close two vectors contaning categorical values are and a technique for determining the center of mass for a set of categorical-valued vectors, we can use a similar algorithm as k-means to find the clusters.\n",
    "\n",
    "The k-modes algorithm:\n",
    "\n",
    "* Select the k initial modes, one for each cluster\n",
    "* In a loop, \n",
    "    * Allocate each point in the data to the nearest cluster based on the dissimilarity measure defined above\n",
    "    * Update the mode of the cluster based on the set of points allocated to it\n",
    "    * Repeat the first step by checking and reallocating each data point based on the new cluster modes\n",
    "    * Repeat until no record changes cluster or the desired number of iteration is reached\n",
    "\n",
    "### Combining k-means and k-modes\n",
    "\n",
    "Combining k-means and k-modes requires a function that combines both the Euclidean distance metric and the dissimilarity measure function. Formally, the function is formulated as \n",
    "\n",
    "<img src=\"./imgs/combined_euc_dissm.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Similar to the k-means and k-modes algorithm above, the optimization problems boils down to finding the cluster vectors (that now contain both numeric and categorical values) such that the sum of the euclidean distance metric and dissimilarity measure across all k cluster vectors is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forced-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-presence",
   "metadata": {},
   "source": [
    "# German Credit Data\n",
    "\n",
    "Source\n",
    "    * https://towardsdatascience.com/clustering-datasets-having-both-numerical-and-categorical-variables-ed91cdca0677\n",
    "    * https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "productive-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    \"chk_acct\",          # 1\n",
    "    \"duration\",          # 2\n",
    "    \"credit_his\",        # 3\n",
    "    \"purpose\",           # 4\n",
    "    \"amount\",            # 5\n",
    "    \"saving_acct\",       # 6\n",
    "    \"present_emp\",       # 7\n",
    "    \"installment_rate\",  # 8\n",
    "    \"sex\",               # 9\n",
    "    \"other_debtor\",      # 10          \n",
    "    \"present_resid\",     # 11\n",
    "    \"property\",          # 12\n",
    "    \"age\",               # 13\n",
    "    \"other_install\",     # 14\n",
    "    \"housing\",           # 15\n",
    "    \"n_credits\",         # 16\n",
    "    \"job\",               # 17\n",
    "    \"n_people\",          # 18\n",
    "    \"telephone\",         # 19\n",
    "    \"foreign\",           # 20\n",
    "    \"response\"           # 21\n",
    "]\n",
    "\n",
    "df = pd.read_csv('./data/german/german.data',\n",
    "                 sep=' ', \n",
    "                 header=None,\n",
    "                 names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [\n",
    "    \"duration\",          # 2\n",
    "    \"amount\",            # 5\n",
    "    \"installment_rate\",  # 8\n",
    "    \"present_resid\",     # 11\n",
    "    \"age\",               # 13\n",
    "    \"n_credits\",         # 16\n",
    "    \"n_people\"           # 18\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functional-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"chk_acct\",          # 1\n",
    "    \"credit_his\",        # 3\n",
    "    \"present_emp\",       # 7\n",
    "    \"sex\",               # 9\n",
    "    \"property\",          # 12\n",
    "    \"housing\"            # 15\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, cont_cols+cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dutch-constant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>20.903</td>\n",
       "      <td>12.058814</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>3271.258</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1365.5</td>\n",
       "      <td>2319.5</td>\n",
       "      <td>3972.25</td>\n",
       "      <td>18424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment_rate</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.973</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present_resid</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.845</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>35.546</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_credits</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.407</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_people</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.155</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean          std    min     25%     50%  \\\n",
       "duration          1000.0    20.903    12.058814    4.0    12.0    18.0   \n",
       "amount            1000.0  3271.258  2822.736876  250.0  1365.5  2319.5   \n",
       "installment_rate  1000.0     2.973     1.118715    1.0     2.0     3.0   \n",
       "present_resid     1000.0     2.845     1.103718    1.0     2.0     3.0   \n",
       "age               1000.0    35.546    11.375469   19.0    27.0    33.0   \n",
       "n_credits         1000.0     1.407     0.577654    1.0     1.0     1.0   \n",
       "n_people          1000.0     1.155     0.362086    1.0     1.0     1.0   \n",
       "\n",
       "                      75%      max  \n",
       "duration            24.00     72.0  \n",
       "amount            3972.25  18424.0  \n",
       "installment_rate     4.00      4.0  \n",
       "present_resid        4.00      4.0  \n",
       "age                 42.00     75.0  \n",
       "n_credits            2.00      4.0  \n",
       "n_people             1.00      2.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cont_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-primary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
